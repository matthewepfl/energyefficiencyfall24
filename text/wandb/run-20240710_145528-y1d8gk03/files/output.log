config.json: 100%|██████████████████████████████| 625/625 [00:00<00:00, 160kB/s]


model.safetensors: 100%|██████████████████████| 714M/714M [00:03<00:00, 181MB/s]
/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
tokenizer_config.json: 100%|█████████████████| 49.0/49.0 [00:00<00:00, 18.4kB/s]
vocab.txt: 100%|█████████████████████████████| 996k/996k [00:00<00:00, 23.2MB/s]
tokenizer.json: 100%|██████████████████████| 1.96M/1.96M [00:00<00:00, 7.28MB/s]









































































































































































































































































































































































































































































































Training: 100%|█████████████████████████████| 2057/2057 [16:24<00:00,  2.09it/s]
Epoch 1/10
Train loss: 1488.0010065459835
Training:   0%|                                        | 0/2057 [00:00<?, ?it/s]
Test loss: 890.9408896423818










































































































































































































































































































































































































































































































Training: 100%|█████████████████████████████| 2057/2057 [16:25<00:00,  2.09it/s]
Epoch 2/10
Train loss: 1130.733766161706
Test loss: 896.6914769264799
Model saved at epoch 2 with test loss 896.6914769264799






































































































































































































































































































































Training:  67%|███████████████████▎         | 1373/2057 [10:56<05:27,  2.09it/s]
Traceback (most recent call last):
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/train_expanded_text.py", line 216, in <module>
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/train_expanded_text.py", line 182, in train
    print(f'Train loss: {train_loss}')
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/train_expanded_text.py", line 118, in train_epoch
    attention_mask = d["attention_mask"].to(device)
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib/python3.9/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/train_expanded_text.py", line 61, in __getitem__
    add_special_tokens=True,
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2945, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 3053, in _call_one
    return self.encode_plus(
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 3127, in encode_plus
    return self._encode_plus(
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib/python3.9/site-packages/transformers/tokenization_utils.py", line 788, in _encode_plus
    first_ids = get_input_ids(text)
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib/python3.9/site-packages/transformers/tokenization_utils.py", line 755, in get_input_ids
    tokens = self.tokenize(text, **kwargs)
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib/python3.9/site-packages/transformers/tokenization_utils.py", line 650, in tokenize
    tokens = self.tokens_trie.split(text)
  File "/scratch/izar/mmorvan/EnergyEfficiencyPredictionMatthew/text/venv/lib/python3.9/site-packages/transformers/tokenization_utils.py", line 237, in split
    for start in to_remove:
KeyboardInterrupt